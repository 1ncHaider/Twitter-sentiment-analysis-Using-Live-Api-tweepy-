{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eae4cec",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis\n",
    "\n",
    "This notebook demonstrates a complete Twitter sentiment analysis pipeline using live API data collection, preprocessing, model training, evaluation, and prediction.\n",
    "\n",
    "**Technologies used:** Tweepy, Pandas, Scikit-learn, Joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce73bbf7",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Install necessary libraries if you haven't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3570b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install packages if running in a fresh environment\n",
    "# %pip install tweepy python-dotenv pandas scikit-learn joblib\n",
    "\n",
    "import tweepy\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f38bf8",
   "metadata": {},
   "source": [
    "## Fetch Tweets\n",
    "\n",
    "Fetch tweets using Twitter API. Make sure you have your `.env` file set up with your API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc704737",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "API_SECRET = os.getenv(\"API_SECRET\")\n",
    "ACCESS_TOKEN = os.getenv(\"ACCESS_TOKEN\")\n",
    "ACCESS_SECRET = os.getenv(\"ACCESS_SECRET\")\n",
    "\n",
    "auth = tweepy.OAuth1UserHandler(API_KEY, API_SECRET, ACCESS_TOKEN, ACCESS_SECRET)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "def fetch_tweets(query, count=100):\n",
    "    tweets = tweepy.Cursor(api.search_tweets, q=query, lang=\"en\", tweet_mode='extended').items(count)\n",
    "    tweet_data = []\n",
    "    for tweet in tweets:\n",
    "        tweet_data.append(tweet.full_text)\n",
    "    df = pd.DataFrame(tweet_data, columns=['text'])\n",
    "    df.to_csv('data/tweets.csv', index=False)\n",
    "    print(f\"Saved {len(tweet_data)} tweets to data/tweets.csv\")\n",
    "\n",
    "# Uncomment to fetch tweets live\n",
    "# fetch_tweets(\"OpenAI\", 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd34db8",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Clean tweet text by removing URLs, mentions, hashtags, special characters, and lowercasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca6b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df = pd.read_csv('data/tweets.csv')\n",
    "df['cleaned'] = df['text'].apply(clean_text)\n",
    "df.to_csv('data/cleaned_tweets.csv', index=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b372d8a",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "Visualize word frequency and tweet examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51edf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "all_words = ' '.join(df['cleaned']).split()\n",
    "word_freq = Counter(all_words)\n",
    "common_words = word_freq.most_common(20)\n",
    "\n",
    "words, counts = zip(*common_words)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=list(words), y=list(counts))\n",
    "plt.title(\"Top 20 Most Common Words\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b79c323",
   "metadata": {},
   "source": [
    "## Train Sentiment Model\n",
    "\n",
    "Label tweets with simple rules and train a Logistic Regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22770179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentiment(text):\n",
    "    positive_keywords = ['love', 'amazing', 'wonderful', 'fantastic', 'helpful', 'great']\n",
    "    negative_keywords = ['terrible', 'hate', 'worst', 'disappointed', 'bug', 'crash', 'bad']\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    if any(word in text_lower for word in positive_keywords):\n",
    "        return 1\n",
    "    elif any(word in text_lower for word in negative_keywords):\n",
    "        return 0\n",
    "    else:\n",
    "        return 2  # Neutral/unknown\n",
    "\n",
    "df['sentiment'] = df['cleaned'].apply(label_sentiment)\n",
    "df = df[df['sentiment'] != 2]\n",
    "\n",
    "X = df['cleaned']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(f\"Training accuracy: {pipeline.score(X_train, y_train):.2f}\")\n",
    "print(f\"Test accuracy: {pipeline.score(X_test, y_test):.2f}\")\n",
    "\n",
    "joblib.dump(pipeline, 'models/sentiment_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01837111",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Visualize confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e43378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Positive\", \"Negative\"])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac08137",
   "metadata": {},
   "source": [
    "## Predict on New Text\n",
    "\n",
    "Enter new text to get sentiment prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ee153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model_path='models/sentiment_model.pkl'):\n",
    "    model = joblib.load(model_path)\n",
    "    prediction = model.predict([text])[0]\n",
    "    sentiment_map = {0: \"Negative\", 1: \"Positive\"}\n",
    "    return sentiment_map.get(prediction, \"Neutral/Unknown\")\n",
    "\n",
    "sample_text = \"I love using OpenAI's tools!\"\n",
    "print(f\"Text: {sample_text}\")\n",
    "print(f\"Predicted Sentiment: {predict_sentiment(sample_text)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e255e9",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You now have a full Twitter sentiment analysis pipeline from data collection to prediction.\n",
    "\n",
    "Feel free to improve the labeling, add more data, or try different models!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

